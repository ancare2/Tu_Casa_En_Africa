import express from 'express';
import cors from 'cors';
import bodyParser from 'body-parser';
import fetch from 'node-fetch';
import dotenv from 'dotenv'; // ‚ö†Ô∏è necesario

// --- Cargar variables de entorno solo en desarrollo ---
if (process.env.NODE_ENV !== 'production') {
  dotenv.config();
  console.log('‚úÖ Variables cargadas desde .env');
}

// --- DEBUG: imprimir variable OPENAI_API_KEY ---
console.log('üîç DEBUG: process.env.OPENAI_API_KEY:',
  process.env.OPENAI_API_KEY ? '[OK]' : '[NO DEFINIDA]');
  console.log('üîç DEBUG: NODE_ENV:', process.env.NODE_ENV);
  console.log('üîç Variables de entorno:', process.env);

const app = express();

// --- Comprobar variable de entorno ---
if (!process.env.OPENAI_API_KEY) {
  console.error('‚ùå ERROR: La variable OPENAI_API_KEY no est√° definida. Revisa tu configuraci√≥n en Railway.');
  process.exit(1); // Detiene la app si no hay API key
}

const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
const SECRET_TOKEN = process.env.SECRET_TOKEN || null;

console.log('üîë OPENAI_API_KEY est√° definida ‚úÖ');

// --- CORS: solo frontend deployado ---
const allowedOrigin = 'https://tucasaenafrica-africa.up.railway.app';
app.use(cors({ origin: allowedOrigin }));

app.use(bodyParser.json());

// --- Helper para enviar prompt a OpenAI ---
async function fetchOpenAI(prompt) {
  console.log('‚û°Ô∏è Enviando prompt a OpenAI (truncado a 500 chars):');
  console.log(prompt.slice(0, 500) + (prompt.length > 500 ? '... [truncado]' : ''));

  const response = await fetch('https://api.openai.com/v1/chat/completions', {
    method: 'POST',
    headers: {
      'Authorization': Bearer ${OPENAI_API_KEY},
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      model: "gpt-3.5-turbo",
      messages: [
        { role: "system", content: "Eres un asistente que ayuda a analizar registros m√©dicos de pacientes." },
        { role: "user", content: prompt }
      ],
      max_tokens: 800
    })
  });

  console.log('Status OpenAI:', response.status);

  if (!response.ok) {
    const errorText = await response.text();
    console.error('‚ùå Error del API OpenAI:', errorText);
    throw new Error(OpenAI Error: ${response.status});
  }

  const data = await response.json();
  console.log('Respuesta OpenAI (truncada a 500 chars):', JSON.stringify(data).slice(0, 500));

  return data?.choices?.[0]?.message?.content || null;
}

// --- Ruta POST ---
app.post('/api/generate', async (req, res) => {
  console.log('‚û°Ô∏è Nueva petici√≥n a /api/generate');

  if (SECRET_TOKEN) {
    const token = req.headers['x-api-key'];
    console.log('Token recibido:', token);
    if (token !== SECRET_TOKEN) {
      console.error('‚ùå Token inv√°lido');
      return res.status(401).json({ text: '‚ùå Acceso denegado. Token inv√°lido.' });
    }
  }

  const { prompt, datos } = req.body;
  if (!prompt || !Array.isArray(datos) || datos.length === 0) {
    console.error('‚ùå Prompt vac√≠o o datos no v√°lidos');
    return res.status(400).json({ text: '‚ùå Prompt y datos son obligatorios.' });
  }

  try {
    const BATCH_SIZE = 50;
    const batches = [];
    for (let i = 0; i < datos.length; i += BATCH_SIZE) {
      batches.push(datos.slice(i, i + BATCH_SIZE));
    }

    const res√∫menesParciales = [];
    for (let i = 0; i < batches.length; i++) {
      console.log(‚û°Ô∏è Procesando lote ${i+1}/${batches.length} (registros: ${batches[i].length}));
      const batchPrompt = ${prompt}\n\nDatos del lote ${i+1}:\n${JSON.stringify(batches[i])};
      const resumen = await fetchOpenAI(batchPrompt);
      if (!resumen) {
        console.error(‚ö†Ô∏è Lote ${i+1} sin respuesta);
      } else {
        console.log(‚úÖ Lote ${i+1} procesado);
      }
      res√∫menesParciales.push(resumen);
    }

    console.log('‚û°Ô∏è Combinando res√∫menes parciales...');
    const resumenFinalPrompt = Combina estos res√∫menes parciales en un resumen global √∫nico, coherente y profesional:\n${JSON.stringify(res√∫menesParciales)};
    const resumenGlobal = await fetchOpenAI(resumenFinalPrompt);

    if (!resumenGlobal) {
      console.error('‚ö†Ô∏è No se recibi√≥ resumen global');
      return res.status(500).json({ text: '‚ö†Ô∏è No se recibi√≥ respuesta v√°lida de la IA.' });
    }

    console.log('‚úÖ Resumen global generado');
    res.json({ text: resumenGlobal });

  } catch (err) {
    console.error('‚ùå Error en la generaci√≥n:', err);
    res.status(500).json({ text: '‚ùå Error al conectar con la IA.' });
  }
});

// --- Puerto ---
const PORT = process.env.PORT || 3000;
app.listen(PORT, '0.0.0.0', () => console.log(‚úÖ Servidor escuchando en http://0.0.0.0:${PORT}));
